name: pita_llamacpp_cuda
channels:
  - defaults
  - nvidia
  - conda-forge
dependencies:
  - python=3.12
  - pip
  - cuda-cudart=12.4.127  # CUDA runtime library needed by llama-cpp-python
  - cuda-toolkit=12.4.1   # Use the single meta-package from the nvidia channel
  - cmake                 # Required for building llama-cpp-python from source
  # After activating this environment, install llama-cpp-python with CUDA:
  # export CUDACXX=$CONDA_PREFIX/bin/nvcc
  # export CPATH=$CONDA_PREFIX/targets/x86_64-linux/include:$CPATH
  # export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH
  # CMAKE_ARGS="-DGGML_CUDA=on -DCMAKE_CUDA_FLAGS=-allow-unsupported-compiler" pip install llama-cpp-python --no-cache-dir
